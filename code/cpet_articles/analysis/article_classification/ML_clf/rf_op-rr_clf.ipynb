{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2636eb04-5e9e-4f16-940a-3f4a7b50ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cc3d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/antonhesse/Desktop/Anton/Education/UMN/PhD/Dissertation/CPET_scoping_review/code/cpet_articles/analysis/helper_funcs')\n",
    "from text_analysis import tokenize_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cae8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get txt file paths and stems\n",
    "txt_file_paths = list(Path('/Users/antonhesse/Desktop/Anton/Education/UMN/PhD/Dissertation/CPET_scoping_review/data/cpet_articles/full_texts/txts').glob('*.txt'))\n",
    "txt_file_stems = [path.stem for path in txt_file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceed2f32-d19e-42dc-a908-145a59a40781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load op-rr eligibility data frame\n",
    "op_rr_df = pd.read_csv('/Users/antonhesse/Desktop/Anton/Education/UMN/PhD/Dissertation/CPET_scoping_review/data/cpet_articles/text_analysis/eligibility/Eligibility - op-rr.csv')\n",
    "# drop articles that haven't been assess for op-rr status\n",
    "op_rr_df = op_rr_df[~op_rr_df['op-rr'].isna()].drop_duplicates().reset_index(drop=True)\n",
    "# op_rr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "894b429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather file paths of articles used to build random forest ML model\n",
    "file_paths_for_model = [path for path in txt_file_paths if path.stem in op_rr_df['doi_suffix'].to_list()]\n",
    "file_stems_for_model = [path.stem for path in file_paths_for_model]\n",
    "\n",
    "files_df = pd.DataFrame(\n",
    "    {'doi_suffix': file_stems_for_model,\n",
    "    'file_path': file_paths_for_model}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9aaf88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi_suffix</th>\n",
       "      <th>file_path</th>\n",
       "      <th>op-rr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s00421-007-0554-0</td>\n",
       "      <td>/Users/antonhesse/Desktop/Anton/Education/UMN/...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s40279-021-01523-9</td>\n",
       "      <td>/Users/antonhesse/Desktop/Anton/Education/UMN/...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jbc.m117.817510</td>\n",
       "      <td>/Users/antonhesse/Desktop/Anton/Education/UMN/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ijspp.2013-0486</td>\n",
       "      <td>/Users/antonhesse/Desktop/Anton/Education/UMN/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s12984-018-0401-z</td>\n",
       "      <td>/Users/antonhesse/Desktop/Anton/Education/UMN/...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>s13063-019-3560-8</td>\n",
       "      <td>/Users/antonhesse/Desktop/Anton/Education/UMN/...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>jbc.m112.440354</td>\n",
       "      <td>/Users/antonhesse/Desktop/Anton/Education/UMN/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>chest.107.5.1206</td>\n",
       "      <td>/Users/antonhesse/Desktop/Anton/Education/UMN/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>a-1273-7589</td>\n",
       "      <td>/Users/antonhesse/Desktop/Anton/Education/UMN/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>j.amjcard.2011.11.009</td>\n",
       "      <td>/Users/antonhesse/Desktop/Anton/Education/UMN/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1505 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 doi_suffix  \\\n",
       "0         s00421-007-0554-0   \n",
       "1        s40279-021-01523-9   \n",
       "2           jbc.m117.817510   \n",
       "3           ijspp.2013-0486   \n",
       "4         s12984-018-0401-z   \n",
       "...                     ...   \n",
       "1500      s13063-019-3560-8   \n",
       "1501        jbc.m112.440354   \n",
       "1502       chest.107.5.1206   \n",
       "1503            a-1273-7589   \n",
       "1504  j.amjcard.2011.11.009   \n",
       "\n",
       "                                              file_path  op-rr  \n",
       "0     /Users/antonhesse/Desktop/Anton/Education/UMN/...  False  \n",
       "1     /Users/antonhesse/Desktop/Anton/Education/UMN/...  False  \n",
       "2     /Users/antonhesse/Desktop/Anton/Education/UMN/...   True  \n",
       "3     /Users/antonhesse/Desktop/Anton/Education/UMN/...   True  \n",
       "4     /Users/antonhesse/Desktop/Anton/Education/UMN/...  False  \n",
       "...                                                 ...    ...  \n",
       "1500  /Users/antonhesse/Desktop/Anton/Education/UMN/...  False  \n",
       "1501  /Users/antonhesse/Desktop/Anton/Education/UMN/...   True  \n",
       "1502  /Users/antonhesse/Desktop/Anton/Education/UMN/...   True  \n",
       "1503  /Users/antonhesse/Desktop/Anton/Education/UMN/...   True  \n",
       "1504  /Users/antonhesse/Desktop/Anton/Education/UMN/...   True  \n",
       "\n",
       "[1505 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge files_df with op-rr_df\n",
    "merge_df = pd.merge(files_df, op_rr_df.drop(['file_path', 'pred_op-rr', 'pred_0.5'], axis=1), how='inner', on='doi_suffix')\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90e12bd9-7c29-4a84-aaf3-839d323f0c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520e21f77b64484aaf6fe972b1ba6254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11f7dfb96d94eee9d258cdf94d1421a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize files and join tokens\n",
    "merge_df['tokens'] = merge_df['file_path'].progress_apply(lambda x: tokenize_file(x, mode='lemm'))\n",
    "merge_df['joined_tokens'] = merge_df['tokens'].progress_apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de71bbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vetorizer and model\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "rf_clf = RandomForestClassifier(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc9e9d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model and get current accuracy\n",
    "X = vectorizer.fit_transform(merge_df['joined_tokens'].to_list())\n",
    "rf_clf.fit(X.toarray(), merge_df['op-rr'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "566b681c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   23.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   22.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   16.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   19.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   15.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   15.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   13.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   17.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   14.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   14.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Accuracy: 83.8%\n"
     ]
    }
   ],
   "source": [
    "# uncomment remaining lines to check current accuracy\n",
    "rskf_cv = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 2)\n",
    "scores = cross_val_score(rf_clf, X.toarray(), merge_df['op-rr'].to_list(), cv = rskf_cv)\n",
    "mean_score = round(np.mean(scores),3)*100\n",
    "print(f'Current Accuracy: {mean_score}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb0d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8523d6f-c991-4a71-a5bc-08237b5e14a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bbb articles and remove known ineligible articles\n",
    "all_bbb_articles = pd.read_csv('/Users/antonhesse/Desktop/Anton/Education/UMN/PhD/Dissertation/CPET_scoping_review/data/cpet_articles/text_analysis/bbb_articles.csv')\n",
    "ineligible_articles = pd.read_csv('/Users/antonhesse/Desktop/Anton/Education/UMN/PhD/Dissertation/CPET_scoping_review/data/cpet_articles/text_analysis/eligibility/ineligible_articles_combined.csv')\n",
    "bbb_articles = all_bbb_articles[~all_bbb_articles['doi_suffix'].isin(ineligible_articles['doi_suffix'])].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1289da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find subset of bbb article file stems that are not op_rr_df\n",
    "remaining_bbb_file_paths = [path for path in txt_file_paths if path.stem in bbb_articles['doi_suffix'].to_list() and path.stem not in op_rr_df['doi_suffix'].to_list()]\n",
    "remaining_bbb_file_stems = [path.stem for path in remaining_bbb_file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a34b07e9-d899-4413-9b46-bdf7886d044d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8808fe2d1a27421a82b4daf9354efb08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7896 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_texts = []\n",
    "for path in tqdm(remaining_bbb_file_paths, total=len(remaining_bbb_file_paths)):\n",
    "    try:\n",
    "        tokens = tokenize_file(path, mode='lemm')\n",
    "        if tokens is not None:\n",
    "            joined_tokens = ' '.join(tokens)\n",
    "        test_texts.append(joined_tokens)\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        test_texts.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d12cdfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test data frame\n",
    "test_df = pd.DataFrame({\n",
    "    'doi_suffix': [path.stem for path in remaining_bbb_file_paths],\n",
    "    'file_path': [path for path in remaining_bbb_file_paths],\n",
    "    'joined_tokens': test_texts\n",
    "})\n",
    "test_df = test_df[~test_df['joined_tokens'].isna()].reset_index(drop=True)\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2820786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    9.5s finished\n"
     ]
    }
   ],
   "source": [
    "# create predictions and calculate probabilities\n",
    "X_test = vectorizer.transform(test_texts)\n",
    "preds = rf_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a3a1a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to get info on the prediction classes\n",
    "# print(preds)\n",
    "# print(rf_clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "13221547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output data frame\n",
    "out_df = test_df.drop('joined_tokens', axis=1)\n",
    "\n",
    "out_df['pred_false'] = preds[:,0]\n",
    "out_df['pred_true'] = preds[:,1]\n",
    "out_df['pred_0.5'] = abs(preds[:,0]-0.5)\n",
    "out_df['pred_op-rr'] = out_df.apply(lambda x: False if x['pred_false'] > 0.5 else True, axis=1)\n",
    "out_df.insert(2, 'op-rr', None)\n",
    "\n",
    "out_df = out_df.reindex(columns=['doi_suffix', 'file_path', 'op-rr', 'pred_op-rr', 'pred_0.5'])\n",
    "# out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d139b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate output df with op_rr_df\n",
    "comb_df = pd.concat([op_rr_df, out_df])\n",
    "comb_df = comb_df.sort_values(['op-rr', 'pred_op-rr', 'pred_0.5'], ascending=False).reset_index(drop=True)\n",
    "comb_df['doi_suffix'] = comb_df['doi_suffix'].astype('str')\n",
    "# comb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1db4f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "46b69007",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df.to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b85d73fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df.to_csv(Path(\n",
    "    '/Users/antonhesse/Desktop/Anton/Education/UMN/PhD/Dissertation/CPET_scoping_review/data/cpet_articles/text_analysis/eligibility/pred_op-rr.csv'),\n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa376450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "446a03fef2add5f67b999c04d05da6612f433d57892c44d0763abbe61a1895d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
