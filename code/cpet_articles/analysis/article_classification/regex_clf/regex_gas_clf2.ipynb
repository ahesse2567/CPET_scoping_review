{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0665aac-0060-4b2f-b54a-55b86a8dee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "from langdetect import detect\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37f50e7e-add3-4ce7-81cd-45454faebba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_one_string(file_name, file_list):\n",
    "    txt_re = re.compile(re.escape(file_name))\n",
    "    fname = list(filter(txt_re.search, file_list))[0]\n",
    "    \n",
    "    # check file size to make sure the txt file actually has text\n",
    "    file_size = 0\n",
    "    while file_size == 0:\n",
    "        file_size = Path(fname).stat().st_size\n",
    "        if file_size != 0: # check if conversion to txt didn't work\n",
    "            with open(fname, 'r') as f:\n",
    "                text = f.read()\n",
    "        else:\n",
    "            print('Empty file, returning None')\n",
    "            return None\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    return text_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fe1dc01-61f7-4692-80df-d37f1c40e171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_file(file_name, file_list, mode = 'lemm'):\n",
    "    txt_re = re.compile(file_name)\n",
    "    fname = list(filter(txt_re.search, file_list))[0]\n",
    "    \n",
    "    # check file size to make sure the txt file actually has text\n",
    "    file_size = 0\n",
    "    while file_size == 0:\n",
    "        file_size = Path(fname).stat().st_size\n",
    "        if file_size != 0: # check if conversion to txt didn't work\n",
    "            with open(fname, 'r') as f:\n",
    "                text = f.read()\n",
    "        else:\n",
    "            print('Empty file, returning None')\n",
    "            return None\n",
    "    text_lower = text.lower()\n",
    "    tokens = word_tokenize(text_lower)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    filtered_tokens = [t for t in tokens if t not in stop_words]\n",
    "    \n",
    "    if mode == 'lemm':\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized_words = [lemmatizer.lemmatize(t) for t in filtered_tokens]\n",
    "\n",
    "        return lemmatized_words\n",
    "    \n",
    "    elif mode == 'stem':\n",
    "        stemmer = PorterStemmer()\n",
    "        stemmed_words = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    \n",
    "        return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "398d1964-7e5c-44b8-aca6-9df395708b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oxygen_uptake_re(text):\n",
    "    o2_uptake_consupmtion_re = re.compile(r'oxygen.{0,5}(uptake|consumption)', re.DOTALL)\n",
    "    vo2max_peak_re = re.compile(r'(v)?o2.{0,2}(max|peak)?', re.DOTALL)\n",
    "    aerobic_re = re.compile(r'(?<!an)aerobic.{0,2}(power|capacity)', re.DOTALL)\n",
    "    \n",
    "    mo_list = [\n",
    "        o2_uptake_consupmtion_re.search(text),\n",
    "        vo2max_peak_re.search(text),\n",
    "        aerobic_re.search(text)]\n",
    "    \n",
    "    mentions_o2_uptake = any(mo is not None for mo in mo_list)\n",
    "    \n",
    "    return mentions_o2_uptake\n",
    "\n",
    "def gas_collection_methods_re(text):\n",
    "    bbb_re = re.compile(r'breath.{0,5}breath', re.DOTALL)\n",
    "    douglas_bag_re = re.compile(r'douglas.{0,5}bag', re.DOTALL)\n",
    "    mixing_chamber_re = re.compile(r'mixing.{0,5}chamber', re.DOTALL)\n",
    "    \n",
    "    mo_list = [bbb_re.search(text), douglas_bag_re.search(text), mixing_chamber_re.search(text)]\n",
    "    \n",
    "    gas_methods = any(mo is not None for mo in mo_list)\n",
    "    \n",
    "    return gas_methods\n",
    "\n",
    "def vo2_units_re(text):\n",
    "    vo2_rel_re = re.compile(r'ml([^a-zA-Z]*kg[^a-zA-Z]*min|[^a-zA-Z]*min[^a-zA-Z]*kg)')\n",
    "    # mL_min_kg_re = re.compile(r'ml[^a-zA-Z]*min[^a-zA-Z]*kg')\n",
    "    \n",
    "    # L_mL_min = re.compile(r'(m)?l[^a-zA-Z]*min')\n",
    "\n",
    "    mo_list = [vo2_rel_re.search(text)]\n",
    "    \n",
    "    vo2_units = any(mo is not None for mo in mo_list)\n",
    "    \n",
    "    return vo2_units\n",
    "\n",
    "def estimated_vo2_re(text):\n",
    "    est_o2_uptake_re = re.compile(r'''(\n",
    "    (estimat|indirect|calculat).{0,30}oxygen.{0,2}(uptake|consumption)|\n",
    "    oxygen.{0,2}(uptake|consumption).{0,30}(estimat|indirect|calculat)\n",
    "    )''',\n",
    "                                           re.DOTALL | re.VERBOSE)\n",
    "    \n",
    "    est_vo2_re = re.compile(r'''(\n",
    "    (estimat|indirect|calculat).{0,30}(v)?o2.{0,2}(max|peak)|\n",
    "    (v)?o2.{0,2}(max|peak).{0,30}(estimat|indirect|calculat)\n",
    "    )''',\n",
    "                            re.DOTALL | re.VERBOSE)\n",
    "    \n",
    "    est_vo2_units_re = re.compile(r'''(\n",
    "    (estimat|indirect|calculat).{0,30}ml([^a-zA-Z]*kg[^a-zA-Z]*min|[^a-zA-Z]*min[^a-zA-Z]*kg)|\n",
    "    ml([^a-zA-Z]*kg[^a-zA-Z]*min|[^a-zA-Z]*min[^a-zA-Z]*kg).{0,30}(estimat|indirect|calculat)\n",
    "    )''',\n",
    "                            re.DOTALL | re.VERBOSE)\n",
    "    \n",
    "    mo_list = [est_o2_uptake_re.search(text), est_vo2_re.search(text), est_vo2_units_re.search(text)]\n",
    "    est_vo2 = any(mo is not None for mo in mo_list)\n",
    "    \n",
    "    return est_vo2\n",
    "    # assessment of aerobic capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "622c5177-1250-46b8-9994-7cb16a0478e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file_paths = [str(path) for path in list(Path('/Users/antonhesse/Desktop/Anton/Education/UMN/Lab and Research/HSPL/CPET_scoping_review/data/cpet_articles/full_texts/txts').rglob('*.txt'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c079351-862f-45a1-93fd-5e8754356e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_files = [path.stem for path in list(Path('/Users/antonhesse/Desktop/Anton/Education/UMN/Lab and Research/HSPL/CPET_scoping_review/data/cpet_articles/full_texts/txts').rglob('*.txt'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "151a5fff-868e-46e6-93a5-57cb1b5523a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b4758d1e424bae8191e7ed96e8ca0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "long_word_lists = [process_file_one_string(f, txt_file_paths) for f in tqdm(txt_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee0f610-0d29-46ad-ac8f-46f6fa30df15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73269cf9f3b54adb8183aaf20930ac36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "token_lists = []\n",
    "\n",
    "for word_list in tqdm(long_word_lists):\n",
    "    tokens = word_tokenize(word_list)\n",
    "    filtered_tokens = [t for t in tokens if t not in stop_words]\n",
    "    lemmatized_words = [lemmatizer.lemmatize(t) for t in filtered_tokens]\n",
    "    token_lists.append(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e139b19-7bf0-4e70-89df-dd06afece8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'txt_file': txt_files,\n",
    "                   'article_text': long_word_lists,\n",
    "                    'tokens': token_lists})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be045b4f-61c9-43a3-a894-a9f9d269eb06",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm_notebook' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtqdm_notebook\u001b[49m\u001b[38;5;241m.\u001b[39mpandas()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm_notebook' is not defined"
     ]
    }
   ],
   "source": [
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff369d5a-744a-47cd-b575-6b27237c1315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a358622efc0343268de414c5640e27cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd3b92cbbd64cceb1c6aecb01d26a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68def80fa7514b11947bf84e8278426c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d39c78d9cda4a39b18726b67af49fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['o2_uptake'] = df.progress_apply(lambda x: oxygen_uptake_re(x['article_text']), axis=1)\n",
    "df['vo2_units'] = df.progress_apply(lambda x: vo2_units_re(x['article_text']), axis=1)\n",
    "df['gas_collection_methods'] = df.progress_apply(lambda x: gas_collection_methods_re(x['article_text']), axis=1)\n",
    "df['estimated_vo2'] = df.progress_apply(lambda x: estimated_vo2_re(x['article_text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13791144-ff9d-4a2c-93d0-2ccf76cc4e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['o2_uptake'] == False].shape # these articles are VERY likely to NOT include gas data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "210fcd52-35bd-491a-8def-bf8a1094052b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3425, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['gas_collection_methods'] == True].shape  # these articles are VERY likely to INCLUDE gas data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ac86ad1-6675-4a07-89b7-98568a081fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    df['o2_uptake'] == False,\n",
    "    df['gas_collection_methods'] == True\n",
    "]\n",
    "\n",
    "choices = ['n', 'y']\n",
    "\n",
    "df['gas_data'] = np.select(condlist=conditions, choicelist=choices, default='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf8a9565-b318-4bc2-8aba-8e83c763a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('/Users/antonhesse/Desktop/Anton/Education/UMN/Lab and Research/HSPL/CPET_scoping_review/data/cpet_articles/gas_clf.csv',\n",
    "#          index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33594309-7e78-436d-810c-da33c6df6336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['txt_file', 'article_text', 'tokens', 'o2_uptake', 'vo2_units',\n",
       "       'gas_collection_methods', 'estimated_vo2', 'gas_data'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc85cf54-127c-4107-a185-4fd11f87f24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_text = df[['txt_file', 'o2_uptake', 'vo2_units',\n",
    "                 'gas_collection_methods', 'estimated_vo2', 'gas_data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3cec6c1-6222-4f4a-8129-b69095bfcca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_text.to_csv('/Users/antonhesse/Desktop/Anton/Education/UMN/Lab and Research/HSPL/CPET_scoping_review/data/cpet_articles/gas_clf_no_text.csv',\n",
    "         index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726ef0d6-f797-4376-89c7-c4008f87dffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
