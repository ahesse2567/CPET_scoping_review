{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "44580c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, RepeatedStratifiedKFold\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB,GaussianNB,ComplementNB\n",
    "from statistics import mean\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40c71fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_files = glob.glob('/Users/antonhesse/Desktop/Anton/Education/UMN/Lab and Research/HSPL/CPET_scoping_review/data/cpet_articles/txts/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fd4e99ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_text_df = pd.read_csv('/Users/antonhesse/Desktop/Anton/Education/UMN/Lab and Research/HSPL/CPET_scoping_review/data/cpet_articles/Manual text analysis - Data.csv')\n",
    "manual_text_df['txt_file_name'] = manual_text_df.apply(lambda x: str(x['Article'] + '.txt'), axis=1)\n",
    "manual_text_df = manual_text_df[manual_text_df['Eligible'] == 'e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "142ed604",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_txt_files = manual_text_df['txt_file_name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8e9e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_name, file_list):\n",
    "    txt_re = re.compile(file_name)\n",
    "    fname = list(filter(txt_re.search, file_list))[0]\n",
    "    \n",
    "    # check file size to make sure the txt file actually has text\n",
    "    file_size = 0\n",
    "    while file_size == 0:\n",
    "        file_size = Path(fname).stat().st_size\n",
    "        if file_size != 0: # check if conversion to txt didn't work\n",
    "            with open(fname, 'r') as f:\n",
    "                text = f.read()\n",
    "        else:\n",
    "            print('Empty file, returning None')\n",
    "            return None\n",
    "    text_lower = text.lower()\n",
    "    tokens = word_tokenize(text_lower)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    filtered_tokens = [t for t in tokens if t not in stop_words]\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(t) for t in filtered_tokens]\n",
    "    \n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b307caab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_text(file_name, file_list):\n",
    "    txt_re = re.compile(file_name)\n",
    "    fname = list(filter(txt_re.search, file_list))[0]\n",
    "    \n",
    "    # check file size to make sure the txt file actually has text\n",
    "    file_size = 0\n",
    "    while file_size == 0:\n",
    "        file_size = Path(fname).stat().st_size\n",
    "        if file_size != 0: # check if conversion to txt didn't work\n",
    "            with open(fname, 'r') as f:\n",
    "                text = f.read()\n",
    "        else:\n",
    "            print('Empty file, returning None')\n",
    "            return None\n",
    "    text_lower = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e4e5e9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7791fdddc74c6eab2430619651d936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [process_file(f, txt_files) for f in tqdm(analyzed_txt_files)]\n",
    "joined_words = [' '.join(text) for text in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1cb754ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_data = manual_text_df['Gas data'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "23d7361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = ['The quick brown fox jumped over the lazy dog.',\n",
    "#        'The dog.',\n",
    "#        'The fox.']\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(joined_words, gas_data, test_size=0.25, random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "be1b8d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bbbff188",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = vectorizer.fit_transform(features_train)\n",
    "features_test = vectorizer.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8844761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = vectorizer.fit_transform(joined_words)\n",
    "# vocabulary = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e7fb83c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BNB = BernoulliNB()\n",
    "BNB.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a5e64f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB accuracy: 0.6923076923076923\n",
      "confusion matrix:\n",
      "[[ 0  8]\n",
      " [ 0 18]]\n"
     ]
    }
   ],
   "source": [
    "BNB_pred = BNB.predict(features_test)\n",
    "accuracy_BNB = metrics.accuracy_score(labels_test, BNB_pred)\n",
    "print(\"BernoulliNB accuracy:\", accuracy_BNB)\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(labels_test, BNB_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f330fa89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNB = MultinomialNB()\n",
    "MNB.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "529af98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB accuracy: 0.6923076923076923\n",
      "confusion matrix:\n",
      "[[ 0  8]\n",
      " [ 0 18]]\n"
     ]
    }
   ],
   "source": [
    "MNB_pred = MNB.predict(features_test)\n",
    "accuracy_MNB = metrics.accuracy_score(labels_test, MNB_pred)\n",
    "print(\"BernoulliNB accuracy:\", accuracy_MNB)\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(labels_test, MNB_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee5d0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector = TfidfVectorizer(stop_words='english')\n",
    "# vector.fit(joined_words)\n",
    "# vector.get_feature_names_out()\n",
    "# tfidf = vector.transform(joined_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cbe7bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_transformer = TfidfTransformer()\n",
    "# X_train_tfidf = tfidf_transformer.fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d06a17fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(stop_words='english')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf = vector.transform(joined_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1eefbcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bf4a5704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_clf.fit(X = features_train, y = labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9899c628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<78x29823 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 112336 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
