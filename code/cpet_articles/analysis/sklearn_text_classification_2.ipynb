{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f73a16da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "# from nltk.probability import FreqDist\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "# import requests\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, RepeatedStratifiedKFold, train_test_split\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB,GaussianNB,ComplementNB,CategoricalNB\n",
    "from statistics import mean, stdev\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beffd835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_name, file_list):\n",
    "    txt_re = re.compile(file_name)\n",
    "    fname = list(filter(txt_re.search, file_list))[0]\n",
    "    \n",
    "    # check file size to make sure the txt file actually has text\n",
    "    file_size = 0\n",
    "    while file_size == 0:\n",
    "        file_size = Path(fname).stat().st_size\n",
    "        if file_size != 0: # check if conversion to txt didn't work\n",
    "            with open(fname, 'r') as f:\n",
    "                text = f.read()\n",
    "        else:\n",
    "            print('Empty file, returning None')\n",
    "            return None\n",
    "    text_lower = text.lower()\n",
    "    tokens = word_tokenize(text_lower)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    filtered_tokens = [t for t in tokens if t not in stop_words]\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(t) for t in filtered_tokens]\n",
    "    \n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82ead547",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_files = glob.glob('/Users/antonhesse/Desktop/Anton/Education/UMN/Lab and Research/HSPL/CPET_scoping_review/data/cpet_articles/txts/*.txt')\n",
    "manual_text_df = pd.read_csv('/Users/antonhesse/Desktop/Anton/Education/UMN/Lab and Research/HSPL/CPET_scoping_review/data/cpet_articles/Manual text analysis - Data.csv')\n",
    "manual_text_df['txt_file_name'] = manual_text_df.apply(lambda x: str(x['Article'] + '.txt'), axis=1)\n",
    "# manual_text_df = manual_text_df[(manual_text_df['Eligible'] == 'e') & (manual_text_df['External ref'] == 'n')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e090a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in manual_text_df.iterrows():\n",
    "    if row['Eligible'] != 'e':\n",
    "        row['Gas data'] = 'n'\n",
    "    if row['External ref'] == 'y':\n",
    "        row['Gas data'] = 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ce6d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_txt_files = manual_text_df['txt_file_name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4683895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929fe9e1470e4ad7aed14b04596e0f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/317 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_lists = [process_file(f, txt_files) for f in tqdm(analyzed_txt_files)]\n",
    "joined_word_lists = [' '.join(text) for text in word_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a64513dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Eligible</th>\n",
       "      <th>Eligibility note</th>\n",
       "      <th>External ref</th>\n",
       "      <th>Gas data</th>\n",
       "      <th>Gas Analyzer Type</th>\n",
       "      <th>Outliers</th>\n",
       "      <th>Interpolation type</th>\n",
       "      <th>Interpolation time (s)</th>\n",
       "      <th>Avg type</th>\n",
       "      <th>Avg subtype</th>\n",
       "      <th>Avg amount</th>\n",
       "      <th>Avg MOS</th>\n",
       "      <th>Avg mean type</th>\n",
       "      <th>Data Processing Text</th>\n",
       "      <th>Avg phrase</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>txt_file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Article, Eligible, Eligibility note, External ref, Gas data, Gas Analyzer Type, Outliers, Interpolation type, Interpolation time (s), Avg type, Avg subtype, Avg amount, Avg MOS, Avg mean type, Data Processing Text, Avg phrase, Notes, Unnamed: 17, Unnamed: 18, txt_file_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_text_df[manual_text_df['Gas data'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a66065f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values counts:\n",
      "y    162\n",
      "n    155\n",
      "Name: Gas data, dtype: int64\n",
      "\n",
      "Proportions:\n",
      "y    51.1\n",
      "n    48.9\n",
      "Name: Gas data, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "gas_data = manual_text_df['Gas data'].to_list()\n",
    "counts = manual_text_df['Gas data'].value_counts()\n",
    "print(f'Values counts:\\n{counts}')\n",
    "props = round(manual_text_df['Gas data'].value_counts() / sum(manual_text_df['Gas data'].value_counts()) * 100,1)\n",
    "print()\n",
    "print(f'Proportions:\\n{props}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8174cd9b",
   "metadata": {},
   "source": [
    "You can use CountVectorizier and TfidfTransformer together, or just use TfidfVectorizer because that combines those steps together. With a Pipeline, however, I'm unsure if you need to separate those two steps or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "68757131",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "#     'MultinomialNB',\n",
    "    'BernoulliNB',\n",
    "#     'GaussianNB',\n",
    "#     'ComplementNB',\n",
    "#     'SGDClassifier',\n",
    "#     'SVC',\n",
    "    'Logistic',\n",
    "#     'LinearSVC',\n",
    "    'NuSVC'\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "#     MultinomialNB(),\n",
    "    BernoulliNB(),\n",
    "#     GaussianNB(),\n",
    "#     ComplementNB(),\n",
    "#     SGDClassifier(),\n",
    "    SVC(kernel='linear', degree=3, gamma='auto', probability=True,),\n",
    "    LogisticRegression(),\n",
    "#     LinearSVC(),\n",
    "    NuSVC(probability=True)\n",
    "]\n",
    "\n",
    "scores_df = pd.DataFrame(columns = [\n",
    "    'Metric',\n",
    "#     'MultinomialNB',\n",
    "    'BernoulliNB',\n",
    "#     'GaussianNB',\n",
    "#     'ComplementNB',\n",
    "#     'SGDClassifier',\n",
    "    'SVC',\n",
    "    'Logistic',\n",
    "#     'LinearSVC',\n",
    "    'NuSVC'\n",
    "])\n",
    "scores_df['Metric'] = ['Mean', 'Median', 'Min', 'Max', 'SD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5042604b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22b6506a46344de8bd7bab54041b791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare accuracy of different models\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(joined_word_lists)\n",
    "rskf_cv = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 5)\n",
    "\n",
    "for name, clf in tqdm(zip(names, classifiers), total=len(classifiers)):\n",
    "    clf.fit(X.toarray(), gas_data)\n",
    "    scores = cross_val_score(clf, X.toarray(), gas_data, cv = rskf_cv)\n",
    "    scores_df[name] = [\n",
    "        round(np.mean(scores)*100,1),\n",
    "        round(np.median(scores)*100,1),\n",
    "        round(min(scores)*100,1),\n",
    "        round(max(scores)*100,1),\n",
    "        round(stdev(scores*100),1)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1fabcfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>BernoulliNB</th>\n",
       "      <th>Logistic</th>\n",
       "      <th>NuSVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean</td>\n",
       "      <td>77.9</td>\n",
       "      <td>81.9</td>\n",
       "      <td>81.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Median</td>\n",
       "      <td>77.8</td>\n",
       "      <td>82.5</td>\n",
       "      <td>81.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Min</td>\n",
       "      <td>68.8</td>\n",
       "      <td>75.0</td>\n",
       "      <td>71.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Max</td>\n",
       "      <td>88.9</td>\n",
       "      <td>90.5</td>\n",
       "      <td>90.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SD</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric  BernoulliNB  Logistic  NuSVC\n",
       "0    Mean         77.9      81.9   81.9\n",
       "1  Median         77.8      82.5   81.2\n",
       "2     Min         68.8      75.0   71.4\n",
       "3     Max         88.9      90.5   90.5\n",
       "4      SD          3.8       4.3    5.1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "72dd26fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_analysis_pdfs = glob.glob('/Users/antonhesse/Desktop/Anton/Education/UMN/Lab and Research/HSPL/CPET_scoping_review/data/cpet_articles/pdfs/manual_pdf_analysis/*.pdf')\n",
    "# manual_analysis_pdfs[0].split('/')[-1].replace('.pdf','.txt')\n",
    "\n",
    "manual_analysis_txts = [x.split('/')[-1].replace('.pdf', '.txt') for x in manual_analysis_pdfs]\n",
    "# len(manual_analysis_txts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6fb7aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_intersection(lst1, lst2, output = 'intersection'):\n",
    "    if output == 'intersection':\n",
    "        return list(set(lst1).intersection(lst2))\n",
    "    elif output == 'difference':\n",
    "        return list(set(lst1).difference(lst2))\n",
    "    elif output == 'symmetric_difference':\n",
    "        return list(set(lst1).symmetric_difference(lst2))\n",
    "    else:\n",
    "        print('Bad input, returning None')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46a99ce4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f5dedb6edd401fbb920ab33011d9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_articles = list_intersection(manual_analysis_txts, analyzed_txt_files, output='difference')\n",
    "word_lists_test = [process_file(f, txt_files) for f in tqdm(test_articles)]\n",
    "joined_word_lists_test = [' '.join(text) for text in word_lists_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b3a78cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('BernoulliNB', BernoulliNB()),\n",
       "                             ('Logistic',\n",
       "                              SVC(gamma='auto', kernel='linear',\n",
       "                                  probability=True)),\n",
       "                             ('NuSVC', LogisticRegression())],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [(name, clf) for name, clf in zip(names, classifiers)]\n",
    "estimators\n",
    "vote_soft = VotingClassifier(estimators=estimators, voting='soft')\n",
    "vote_soft.fit(X, gas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c49994fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(joined_word_lists_test)\n",
    "preds = vote_soft.predict_proba(X_test)\n",
    "# SVC_clf = SVC(kernel='linear', degree=3, gamma='auto')\n",
    "# SVC_clf.fit(X, gas_data)\n",
    "# preds = SVC_clf.predict(X_test)\n",
    "# BNB_clf = BernoulliNB()\n",
    "# BNB_clf.fit(X, gas_data)\n",
    "# preds = BNB_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b30aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb98779",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {'article': test_articles, 'pred_n': preds[:,0], 'pred_y': preds[:,1]}\n",
    "test_df = pd.DataFrame.from_dict(test_dict)\n",
    "test_df['article'] = test_df['article'].apply(lambda x: x.replace('.txt', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "de05d609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>pred_n</th>\n",
       "      <th>pred_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>jnnp.37.11.1236</td>\n",
       "      <td>0.699058</td>\n",
       "      <td>0.300942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1517-869220152103137534</td>\n",
       "      <td>0.576079</td>\n",
       "      <td>0.423921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>jaha.118.008837</td>\n",
       "      <td>0.413298</td>\n",
       "      <td>0.586702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>j.1365-2125.1979.tb04720.x</td>\n",
       "      <td>0.411176</td>\n",
       "      <td>0.588824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>hrt.62.6.445</td>\n",
       "      <td>0.391335</td>\n",
       "      <td>0.608665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>hrt.61.2.161</td>\n",
       "      <td>0.390081</td>\n",
       "      <td>0.609919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>fphys.2021.683942</td>\n",
       "      <td>0.376728</td>\n",
       "      <td>0.623272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>ijn.s282200</td>\n",
       "      <td>0.375942</td>\n",
       "      <td>0.624058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>circheartfailure.113.000187</td>\n",
       "      <td>0.375424</td>\n",
       "      <td>0.624576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>hbm.22658</td>\n",
       "      <td>0.369019</td>\n",
       "      <td>0.630981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>hrt.70.1.17</td>\n",
       "      <td>0.352544</td>\n",
       "      <td>0.647456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>hrt.44.3.259</td>\n",
       "      <td>0.343778</td>\n",
       "      <td>0.656222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>circheartfailure.110.944694</td>\n",
       "      <td>0.332978</td>\n",
       "      <td>0.667022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2049-6958-9-20</td>\n",
       "      <td>0.329715</td>\n",
       "      <td>0.670285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>hrt.70.3.247</td>\n",
       "      <td>0.327356</td>\n",
       "      <td>0.672644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>ijms21145162</td>\n",
       "      <td>0.319747</td>\n",
       "      <td>0.680253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>s40279-017-0811-2</td>\n",
       "      <td>0.315433</td>\n",
       "      <td>0.684567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>00140139.2015.1082632</td>\n",
       "      <td>0.314235</td>\n",
       "      <td>0.685765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>archpedi.161.6.561</td>\n",
       "      <td>0.310873</td>\n",
       "      <td>0.689127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>j.jpeds.2012.01.036</td>\n",
       "      <td>0.308481</td>\n",
       "      <td>0.691519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         article    pred_n    pred_y\n",
       "210              jnnp.37.11.1236  0.699058  0.300942\n",
       "21       1517-869220152103137534  0.576079  0.423921\n",
       "79               jaha.118.008837  0.413298  0.586702\n",
       "93    j.1365-2125.1979.tb04720.x  0.411176  0.588824\n",
       "143                 hrt.62.6.445  0.391335  0.608665\n",
       "90                  hrt.61.2.161  0.390081  0.609919\n",
       "106            fphys.2021.683942  0.376728  0.623272\n",
       "149                  ijn.s282200  0.375942  0.624058\n",
       "138  circheartfailure.113.000187  0.375424  0.624576\n",
       "166                    hbm.22658  0.369019  0.630981\n",
       "102                  hrt.70.1.17  0.352544  0.647456\n",
       "195                 hrt.44.3.259  0.343778  0.656222\n",
       "87   circheartfailure.110.944694  0.332978  0.667022\n",
       "193               2049-6958-9-20  0.329715  0.670285\n",
       "103                 hrt.70.3.247  0.327356  0.672644\n",
       "204                 ijms21145162  0.319747  0.680253\n",
       "35             s40279-017-0811-2  0.315433  0.684567\n",
       "77         00140139.2015.1082632  0.314235  0.685765\n",
       "194           archpedi.161.6.561  0.310873  0.689127\n",
       "17           j.jpeds.2012.01.036  0.308481  0.691519"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sort_values(by = 'pred_n', ascending=False).iloc[0:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df9e9931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dict = {'article': test_articles, 'pred': preds[0,1]}\n",
    "# test_df = pd.DataFrame.from_dict(test_dict)\n",
    "# pred_as_n = test_df[test_df['pred'] == 'n']['article']\n",
    "# # pred_as_n.apply(lambda x: x.replace('.txt', '')).to_csv('/Users/antonhesse/Desktop/no_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "32350ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55      j.1365-2125.1979.tb04720.x\n",
       "107                      hbm.22658\n",
       "122                jnnp.37.11.1236\n",
       "137                   hrt.61.2.161\n",
       "141                jaha.118.008837\n",
       "158                    hrt.70.1.17\n",
       "166                   hrt.44.3.259\n",
       "180    circheartfailure.113.000187\n",
       "181              fphys.2021.683942\n",
       "185                   hrt.62.6.445\n",
       "190                    ijn.s282200\n",
       "Name: article, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_as_n.apply(lambda x: x.replace('.txt', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681ca7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
